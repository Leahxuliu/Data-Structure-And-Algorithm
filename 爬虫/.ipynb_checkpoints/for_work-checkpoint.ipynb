{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python 爬虫介绍\n",
    "\n",
    "**参考**   \n",
    "https://www.runoob.com/w3cnote/python-spider-intro.html\n",
    "\n",
    "## 定义\n",
    "* 爬虫：一段自动抓取互联网信息的程序，从互联网上抓取对于我们有价值的信息。\n",
    "* Python 爬虫架构主要由五个部分组成，分别是调度器、URL管理器、网页下载器、网页解析器、应用程序（爬取的有价值数据）。\n",
    "\n",
    "**调度器**   \n",
    "相当于一台电脑的CPU，主要负责调度URL管理器、下载器、解析器之间的协调工作。\n",
    "\n",
    "**URL管理器**   \n",
    "包括待爬取的URL地址和已爬取的URL地址，防止重复抓取URL和循环抓取URL，实现URL管理器主要用三种方式，通过内存、数据库、缓存数据库来实现。\n",
    "\n",
    "**网页下载器**   \n",
    "通过传入一个URL地址来下载网页，将网页转换成一个字符串，网页下载器有urllib2（Python官方基础模块）包括需要登录、代理、和cookie，requests(第三方包)\n",
    "\n",
    "**网页解析器**   \n",
    "将一个网页字符串进行解析，可以按照我们的要求来提取出我们有用的信息，也可以根据DOM树的解析方式来解析。网页解析器有正则表达式（直观，将网页转成字符串通过模糊匹配的方式来提取有价值的信息，当文档比较复杂的时候，该方法提取数据的时候就会非常的困难）、html.parser（Python自带的）、beautifulsoup（第三方插件，可以使用Python自带的html.parser进行解析，也可以使用lxml进行解析，相对于其他几种来说要强大一些）、lxml（第三方插件，可以解析 xml 和 HTML），html.parser 和 beautifulsoup 以及 lxml 都是以 DOM 树的方式进行解析的。\n",
    "\n",
    "**应用程序**   \n",
    "就是从网页中提取的有用数据组成的一个应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-6-c78f284743c1>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-c78f284743c1>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    print(len(response1.read())\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "#urllib2 实现下载网页的三种方式\n",
    "\n",
    "#!/usr/bin/python\n",
    "# -*- coding: UTF-8 -*-\n",
    " \n",
    "import cookielib\n",
    "import urllib2\n",
    " \n",
    "url = \"http://www.baidu.com\"\n",
    "response1 = urllib2.urlopen(url)\n",
    "print(\"第一种方法\")\n",
    "#获取状态码，200表示成功\n",
    "print(response1.getcode())\n",
    "#获取网页内容的长度\n",
    "print(len(response1.read())\n",
    " \n",
    "print(\"第2种方法\")\n",
    "request = urllib2.Request(url)\n",
    "#模拟Mozilla浏览器进行爬虫\n",
    "request.add_header(\"user-agent\",\"Mozilla/5.0\")\n",
    "response2 = urllib2.urlopen(request)\n",
    "print(response2.getcode())\n",
    "print(len(response2.read()))\n",
    " \n",
    "print(\"第三种方法\")\n",
    "cookie = cookielib.CookieJar()\n",
    "#加入urllib2处理cookie的能力\n",
    "opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cookie))\n",
    "urllib2.install_opener(opener)\n",
    "response3 = urllib2.urlopen(url)\n",
    "print(response3.getcode())\n",
    "print(len(response3.read()))\n",
    "print(cookie)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
